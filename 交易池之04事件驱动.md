
---

# 专题四：事件驱动、Reset 机制与状态同步

## 概览

TxPool 作为交易缓存层必须对链状态变化（新块到达或回滚）作出快速、一致的响应；这由事件驱动（链头订阅）触发 `Reset(oldHead,newHead)`，并由 TxPool 协调各子池（LegacyPool/BlobPool）执行清理、晋升、驱逐等动作。整个过程必须在并发环境下保持一致、可恢复，并避免 races 导致的丢包或重复上链。

---

## 1. 事件驱动模型：谁发布、谁订阅、事件语义

### 1.1 事件来源

* **链同步器 / consensus / blockchain manager**：当节点接收到新块（包括重组情况）并将其认定为新 canonical head 时，会发布链头更新事件。通常此发布是通过事件总线（`event.Feed`，或自定义 channel/pubsub）完成。
* 在 Geth 中，核心发布者是 `core/blockchain` 或 `consensus` 层，TxPool 订阅该事件来触发 Reset。

  * 事件通常包含：`oldHead`、`newHead`（可包含 headers、blockNumber 等），以及必要的上下文（例如 reorg depth 或是否为 fast reorg）。

### 1.2 TxPool 的订阅

* TxPool 在初始化时订阅链头更新事件（`chainHeadFeed.Subscribe(...)` 或类似接口）。
* 订阅通常是异步回调或带缓冲的 channel，以便发布者不会阻塞主链推进流程。

### 1.3 事件语义（重要）

* **正常推进（no-reorg）**：`oldHead` 是 `newHead.Parent`，新块在 canonical chain 上附加；Reset 主要删除已上链 tx、晋升 queue→pending。
* **短 reorg**：`oldHead` 与 `newHead` 的差距小但不为父子关系（例如发生重组），Reset 需要把此前认为已打包的 tx 恢复到池中（若仍有效），并处理可能重复或冲突的 tx。
* **深度 reorg / chain reorg**：需要更复杂的处理，可能需要基于 receipts/history 的精确判断哪些 tx 被永久取消，哪些需恢复。
* **快速连续头变更**：TxPool 应具备合并/去抖（debounce）策略，避免在短时间内重复做大量 Reset 导致性能问题。

---

## 2. Reset 的目标与高层步骤

### 2.1 Reset 的目标

在 `Reset(oldHead,newHead)` 执行结束后，池应满足：

1. **所有已包含在 canonical chain（<= newHead）的 tx 从池中删除**（不能再当作待打包 tx）
2. **account nextNonce / pending 连续性与链状态一致**（即Per-account pending 的起点应是 chain nonce + n pending）
3. **queue 中因 nonce gap 消失的 tx 晋升为 pending（可打包）**
4. **被回滚的上链 tx（发生 reorg）若仍有效应恢复到池中**
5. **全局索引 / heap / counts / journal 等一致更新**
6. **子池之间隔离性保持**（每个子池以自己的规则处理其队列）

### 2.2 高层步骤（协调器视角）

1. **接收链头变化事件**（可能在独立 goroutine）
2. **计算变更范围**：确定被移除（old blocks not in new chain）与被添加的 blocks（new chain portion）
3. **将 Reset 请求广播给所有子池**（按子池顺序或并行调用）
4. **等待子池完成 Reset**（或采用超时与回退策略）
5. **合并并重建全局数据结构**（price heap、global counts、broadcast queues）
6. **通知上游（miner/p2p）新 pool 状态**（例如 notify miner 更新 candidate txs）

---

## 3. 详细实现：Reset 的时序与每步说明

下面给出更详细的流程，同时提供伪代码。

### 3.1 事件到达（订阅回调）

* **入口**：TxPool 在住循环中，监听 `chainHeadEvent`。
* 为避免在回调阻塞链处理，常见做法是把 `head` 事件写入一个 buffered channel，由一个单独的 worker loop 以串行化方式处理 Reset 操作（可减少并发冲突）。

伪代码（订阅/接收）：

```go
func (p *TxPool) loop(head *types.Header, chain BlockChain) {
  // 1. 交易池的主循环中订阅区块头事件
	// Subscribe to chain head events to trigger subpool resets
	var (
		newHeadCh  = make(chan core.ChainHeadEvent)
		newHeadSub = chain.SubscribeChainHeadEvent(newHeadCh)
	)
	defer newHeadSub.Unsubscribe()

  // ...
		select {
		case event := <-newHeadCh:
			// Chain moved forward, store the head for later consumption
      // 2. 接收新区块头
			newHead = event.Block.Header()
  // ...
		if newHead != oldHead || resetForced {
			// Try to inject a busy marker and start a reset if successful
			select {
			case resetBusy <- struct{}{}:
				// Busy marker injected, start a new subpool reset
        // 3. 这里触发调用子池的Reset
				go func(oldHead, newHead *types.Header) {
					for _, subpool := range p.subpools {
						subpool.Reset(oldHead, newHead)
					}
					resetDone <- newHead
				}(oldHead, newHead)
```

### 3.2 主 Reset loop（串行化处理）

* 单线程/串行化处理 Reset 可显著简化并发问题（但要注意可能成为瓶颈）。常见模式为“head worker goroutine”。

参考上面一小节的内容，通过 resetDone 这个管道，保证串行化处理。


### 3.3 计算变更范围（diff old/new）

* 若 `oldHead == newHead.Parent` 简单追加，不需恢复 rollback tx；
* 若重组，必须查 `common ancestor`（lowest common ancestor）：

伪代码：

```go
ancestor := blockchain.FindCommonAncestor(oldHead, newHead)
removedBlocks := blocksBetween(ancestor, oldHead) // blocks removed
addedBlocks   := blocksBetween(ancestor, newHead) // new canonical blocks
```

* 对于 removedBlocks（即被回滚的块），需要从它们的 receipts/header 中提取出交易列表，做恢复候选（但需验证这些交易仍然有效：nonce、balance 等）；
* 对于 addedBlocks，则这些块包含的 tx 必须从池中删除（if present）。

### 3.4 通知子池 Reset（并发或顺序？）

两种策略：

* **并行通知**：向所有子池并发发送 `Reset(oldHead,newHead)` 并等待它们完成（需保证子池内部线程安全）。

  * 优点：速度快（子池独立处理）。
  * 缺点：并发可能增加锁复杂度。
* **串行通知**：按固定顺序（e.g., LegacyPool -> BlobPool）调用 `Reset`。

  * 优点：简单、安全。
  * 缺点：可能较慢。

通常实现会选择并行但在每个子池内保证线程安全（子池自行负责同步）。

伪代码（并行）：

```go
wg := sync.WaitGroup{}
for _, pool := range tp.pools {
  wg.Add(1)
  go func(p Pool) {
    defer wg.Done()
    p.Reset(oldHead, newHead)
  }(pool)
}
wg.Wait()
```

### 3.5 子池 Reset 的职责（以 LegacyPool 为例）

子池的 Reset 一般包含：

1. **移除已上链 tx**：根据 addedBlocks 的 tx list，或直接用 canonical mapping（blockNumber→blockHash→body）来检测并删除池中已上链 tx。

   * 优先用 blockHash mapping（更稳定）；若使用 txHash 比对更方便。
2. **检查被回滚的 tx（from removedBlocks）并尝试恢复**：

   * 从 removedBlocks 中获取 tx hashes；对每个 tx：

     * Re-validate（nonce、balance、intrinsicGas等）；
     * 如果仍然 valid，则 re-insert 到 pool（通常以 `Add` 路径或专门的恢复路径 – 避免再次广播）。
3. **更新 per-account nextNonce**：对每个受影响 account 重新计算 `nextNonce`：

   * `chainNonce = state.GetNonce(address)` // re-read from chain
   * new `expectedPendingBase = chainNonce + countOfPendingOnChain` (or other logic)
4. **Promote queue → pending**：对于每个 account，尝试把 queue 中的 tx 晋升（从最小 nonce 开始，直到遇到 gap）。
5. **重构 priceHeap / indexes**：删除 heap 中的 entries for removed txs，重建 heap 或 incremental update。
6. **Persist journal / local tx handling**：对本地 tx 要注意不要误删或重复删除，journal 恢复逻辑应在 Reset 后确保一致性。
7. **统计 & metrics 更新**。

伪代码（LegacyPool.Reset）：

```go
func (lp *LegacyPool) Reset(oldHead, newHead *types.Header) {
    lp.lock()
    defer lp.unlock()

    // Build set of txs to remove (from addedBlocks)
    removed := lp.findTxsIncludedInBlocks(addedBlocks)
    for txHash := range removed {
        lp.removeTx(txHash)
    }

    // handle removedBlocks (reorg): attempt to restore those txs
    for _, blk := range removedBlocks {
        for _, tx := range blk.Transactions {
            if lp.hasTx(tx.Hash()) { continue }
            if lp.revalidate(tx) {
                lp.addRecovered(tx)
            }
        }
    }

    // recompute account nextNonce and promote queues
    for addr, acct := range lp.accounts {
        acct.recomputeNextNonce(chainState)
        acct.promote()
    }

    // rebuild heap if necessary
    lp.rebuildHeapIfNeeded()
}
```

### 3.6 子池 Reset 的职责（以 BlobPool 为例）

BlobPool Reset 类似，但还需要处理磁盘 payload：

* 删除已包含的 blob tx metadata，且可能立即标记对应 payload 可删除或 schedule GC；
* 尝试恢复被回滚的 blob tx（需要判断 payload 是否还存在且未被 GC）；
* 若 payload 在 disk 且被回滚 tx 仍有效，则把 meta 恢复到 in-memory queue；
* 对于被标记回收但又需要恢复的 payload，需要谨慎（优先不删除立即恢复的 payload）。

---

## 4. Reorg / 恢复策略细节（恢复优先级与去重）

### 4.1 恢复哪些 tx？

* 仅恢复那些来自 removedBlocks 的 tx（即曾短暂处于 canonical 的 tx），并且在当前 newHead 下仍然 valid。
* 优先恢复本地 tx（local=true），因为用户期望保留。
* 对于冲突 tx（例如两个 tx 都在被回滚块中，但现在会有 nonce 冲突），需要按 fee 或 timestamp 选择保留者。

### 4.2 去重（避免重复上链）

* 恢复路径不应该再次广播这些 tx（除非策略需要）。否则可能引起浪费或 double-inclusion。
* 通常策略：

  * 重新入池但**不自动广播**；等待用户或 miner pull（或在下次广播周期发现仍有效后才广播）。
  * 或广播但标记为 "replay" 并限制频率。

### 4.3 reorg 深度大时的处理

* 若 reorg depth 很深（比如多百块），恢复的 tx 数量可能很大：

  * 避免一次性恢复全部 tx（会导致 IO & memory 突增）。
  * 采用分批恢复，或只恢复 local tx & 高 fee tx，其余按需恢复。
  * 记录 metrics 与日志以便运维决策。

---

## 5. 并发、一致性与锁策略

Reset 与 Add/Replace/Remove 等操作存在竞态，必须通过锁或设计来保证一致性。

### 5.1 常见实现策略

* **headLoop 单线程**（串行 Reset） + **Add/Remove 使用细粒度锁**：

  * 好处：Reset 不会与其他 Reset 并发，减少复杂度；
  * Add 仍可并发，但在写全局索引时需 acquire lock（或使用 CAS style）。
* **combined locks**：对全局 indices 使用 RWMutex（Reset 使用 write lock，读/queries 使用 read lock）。
* **per-account locks**：Add/Promote 对单账户加小范围锁以减少阻塞。
* **atomic swap**：对于某些全局结构（heap），可以在 Reset 中构造新的 heap 后用 atomic pointer swap 替换旧对象，减少阻塞时间。

### 5.2 Locking pitfalls

* 长时间持有全局锁会阻塞 Add / miner 获取交易，降低吞吐；
* Reset 中的 IO 或复杂恢复操作应在释放主要锁后异步完成（先在内存标记，然后分步 cleanup）。

推荐方案（实践）：

1. 在 Reset 中先 **计算变更集**（no heavy locking）
2. 获取必要的 locks（per-account 或 global）以做结构性修改（短时间）
3. 释放 locks
4. 异步做 IO-heavy 清理（如 journal flush、disk GC）

---

## 6. 错误处理与鲁棒性

### 6.1 Reset 时可能遇到的错误

* 无法读取 blocks/receipts（IO error）：

  * 策略：重试或记录并跳过；避免阻塞 Reset loop（报告错误并继续处理其他子池）
* 恢复 tx 在 re-validation 失败：

  * 丢弃并记录原因（balance insufficient、nonce too low/high等）
* Blob payload 在 disk 已被 GC：

  * 标记该 tx 无法恢复
* 子池 Reset 超时或 panic：

  * TxPool Coordinator 应提供 timeout/abort 机制并可重试或 fallback，避免单个子池阻断整体功能。

### 6.2 一致性修复（在异常后）

* 如果 Reset 操作中断或失败，需保证不会留下半一致（half-consistent）状态：

  * 使用事务式更新（若涉及 LevelDB / journal）；
  * 或采用标志位/epoch，只有在 epoch 完整提交后才把新 index 曝露给其他组件。
* 强烈推荐在 Reset 中对外只在完成后发布“ResetComplete”事件。

---

## 7. 调试与运维建议

### 7.1 日志

* 在 Reset start/finish 打明显日志，记录 oldHead/newHead height/hash、removed & added counts、duration
* 在子池 Reset 内记录详细 metric：removedTxs, restoredTxs, evictedDuringReset
* 对于 reorg 恢复，记录每条恢复 tx 的 reason（why restored / failed)

### 7.2 指标

* `txpool.reset.duration`（histogram）
* `txpool.reset.recovered_txs`
* `txpool.reset.removed_txs`
* `txpool.reset.failures`
* `txpool.pending.count` / `txpool.queue.count`

### 7.3 配置建议

* `reset.maxWorkPerCycle`：若常有深度重组，限制每次 Reset 恢复/重算的最大工作量（分批处理）
* `reset.timeout`：对子池 Reset 操作设置超时
* `reset.debounceMs`：短时多次头更新合并（防抖），避免频繁 Reset

---

## 8. 相关源码

> 以下为你在源码中应重点查看的模块/函数（名称基于常见结构，具体文件可能略异）：

* **事件订阅 / 发布**：

  * `core/blockchain` 或 `eth/downloader` 发布 head events（搜索 `SubscribeChainHeadEvent`, `chainHeadFeed`）
* **TxPool coordinator**：

  * `core/txpool/txpool.go`：查找 `Start`, `Subscribe`, `headLoop`, `Reset` 调用点
* **LegacyPool Reset**：

  * `core/txpool/legacypool/legacypool.go`：实现 Reset 方法
* **BlobPool Reset**：

  * `core/txpool/blobpool/blobpool.go`：实现 Reset 与 disk cleanup
* **journal / persistence**：

  * `core/txpool/legacypool/journal.go`：持久化操作与恢复
* **chain access helpers**：

  * `core/rawdb`、`core/blockchain`：用于读 blocks/receipts（Reset 需读取这些）
* **miner interaction**：

  * `miner/worker.go`：看 miner 如何关注 pool 变化（订阅 / pull）

---

## 9. 示例：从事件到 Reset 的完整逻辑

下面是伪码，和真是代码并非一一对应：

```go
// TxPool.start: setup
func (tp *TxPool) Start() {
    tp.headCh = make(chan HeadEvent, 128)
    // 订阅区块头
    sub := blockchain.SubscribeChainHeadEvent()
    go tp.headReceiver(sub) 
    go tp.headLoop()        //序列处理
}

func (tp *TxPool) headReceiver(sub subscription) {
    for ev := range sub.Chan() {
        // 推送到管道进行序列处理
        select {
        case tp.headCh <- ev:
        default:
            // 管道满时，丢弃最老的区块
            log.Warn("headCh full; dropping head event")
        }
    }
}

func (tp *TxPool) headLoop() {
    for ev := range tp.headCh {
        // debounce: wait briefly to merge multiple head events
        time.Sleep(tp.resetDebounce)
        // drain subsequent events
        latest := ev
        for {
            select {
            case e := <-tp.headCh:
                latest = e
            default:
                goto PROCESS
            }
        }
        PROCESS:
        tp.processHeadChange(latest)
    }
}

func (tp *TxPool) processHeadChange(ev HeadEvent) {
    // 计算要增加或删除的区块
    oldHead, newHead := ev.Old, ev.New
    ancestor := tp.blockchain.FindCommonAncestor(oldHead, newHead)
    removed := tp.blockchain.GetBlocksBetween(ancestor, oldHead)
    added   := tp.blockchain.GetBlocksBetween(ancestor, newHead)

    // parallel Reset of subpools
    var wg sync.WaitGroup
    for _, p := range tp.pools {
       wg.Add(1)
       go func(pool Pool) {
           defer wg.Done()
           pool.Reset(removed, added)
       }(p)
    }
    wg.Wait()

    tp.rebuildGlobalIndexes()
    tp.notifyMiner()
}
```

---

## 10. 总结

* **Reset 是 TxPool 与链同步的桥梁**：必须既快速又可靠地反映链状态变更。
* **事件驱动 + 串行化处理** 是安全且实践良好的做法：把 Reset 的复杂性集中在单个 worker loop，可以显著简化并发问题。
* **计算变更集（added/removed blocks）后并行调用子池 Reset** 可以获得性能与隔离性优势，但子池实现必须是线程安全的。
* **在 reorg 场景下优先恢复本地 & 高优先 tx，避免一次性恢复大量 tx 导致 OOM/IO 流量**。
* **日志/metrics 与防抖(timeout/debounce)** 是保障稳定性的关键。
* **Reset 的正确性依赖于对 canonical chain 的精确查询（blocks/receipts）和对池中 tx 的逐条 re-validation**。

---
